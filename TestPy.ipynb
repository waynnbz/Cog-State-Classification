{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config (to be imported from separate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category & headers\n",
    "CATEGORY = {'low':0, 'medium':1, 'high':2, 'baseline':3, 'channelized':4, 'surprise':5}\n",
    "REV_CATEGORY = { v:k for k,v in CATEGORY.items()}\n",
    "OUTPUT_HEADER = ['timestamp', 'test_suite', 'predicted_induced_state',\n",
    "       'three_sec_predicted_induced_state',\n",
    "       'predicted_induced_state_confidence',\n",
    "       'three_sec_predicted_induced_state_confidence', 'top_three_features']\n",
    "\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softprob',  # 多分类的问题\n",
    "    'num_class': 6,               # 类别数，与 multisoftmax 并用\n",
    "    'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample': 0.7,              # 随机采样训练样本\n",
    "    'colsample_bytree': 0.7,       # 生成树时进行的列采样\n",
    "    'min_child_weight': 3,\n",
    "#     'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.007,                  # 如同学习率\n",
    "    'seed': 1000,\n",
    "#     'nthread': 4,                  # cpu 线程数\n",
    "}\n",
    "\n",
    "# number of iteration for model training\n",
    "NUM_ROUND = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper (separate file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_time(time_serie):\n",
    "    time_serie = pd.to_numeric(time_serie)\n",
    "    time_serie = time_serie.apply(lambda x: datetime.datetime.fromtimestamp(x/1000000))\n",
    "    time_serie = time_serie.dt.round('1s')\n",
    "    time_serie = time_serie.apply(lambda x: int(datetime.datetime.timestamp(x)*1000000))\n",
    "#     time_serie = time_serie.drop_duplicates()\n",
    "    \n",
    "    return time_serie\n",
    "\n",
    "# return the mode(most comm) element in a series\n",
    "def mode(series):\n",
    "    return series.value_counts().index[0]\n",
    "\n",
    "# return the mean value excluding -9999.9 the default value, if there's normal values\n",
    "def normal_mean(series):\n",
    "    if series.nunique() > 1:\n",
    "        return series[series > -9999.9].mean()\n",
    "    return series.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data path\n",
    "TEST_PATH = 'data/data_training.csv'\n",
    "# OUTPUT PATH\n",
    "OUTPUT_PATH = ''\n",
    "# MODEL PATH\n",
    "MODEL_PATH = 'submissions/output/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    if len(sys.argv) < 2 or len(sys.argv[1]) == 0:\n",
    "        print(\"Testing input file is missing.\")\n",
    "        return 1\n",
    "    \n",
    "    if len(sys.argv) < 3 or len(sys.argv[2]) == 0:\n",
    "        print(\"Testing output file is missing.\")\n",
    "        return 1\n",
    "    \n",
    "    print('Testing started.')\n",
    "\n",
    "    input_file = sys.argv[1]\n",
    "    output_file = sys.argv[2]\n",
    "    model_file = sys.argv[3]\n",
    "    \n",
    "    # My Code Starts HERE\n",
    "    \n",
    "    test_df = load_data_in_chunks(input_file)#, chunksize=10000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################################################\n",
    "\n",
    "    test_data = pd.read_csv(input_file)\n",
    "    model_data = pd.read_csv(model_file)\n",
    "\n",
    "    final_cols = test_data.columns.tolist()\n",
    "    model_cols = model_data.columns.tolist()\n",
    "    target = model_cols[0]\n",
    "    columns = model_cols[1:]\n",
    "\n",
    "    df = test_data.copy()\n",
    "    df['timestamp'] = pd.to_numeric(df['time'])\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x/1000000))\n",
    "    df['timestamp'] = df['timestamp'].dt.round('1s')\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: int(datetime.datetime.timestamp(x)*1000000))\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    \n",
    "    submission_data = df[['timestamp','test_suite']].copy()\n",
    "    submission_data = submission_data.drop_duplicates()\n",
    "    submission_data = submission_data.reset_index(drop=True)\n",
    "\n",
    "    category = {0:'low', 1:'medium', 2:'high', 3:'baseline', 4:'channelized', 5:'surprise'}\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(model_data[columns], model_data[target])\n",
    "\n",
    "    test_data['predicted_induced_state'] = np.rint(model.predict(test_data[columns]))\n",
    "    test_data[\"predicted_induced_state\"] = test_data[\"predicted_induced_state\"].replace(category)\n",
    "\n",
    "    test_data['three_sec_predicted_induced_state'] = np.rint(model.predict(test_data[columns]))\n",
    "    test_data[\"three_sec_predicted_induced_state\"] = test_data[\"three_sec_predicted_induced_state\"].replace(category)\n",
    "\n",
    "    submission_data['predicted_induced_state'] = test_data[\"predicted_induced_state\"]\n",
    "    submission_data['three_sec_predicted_induced_state'] = test_data[\"three_sec_predicted_induced_state\"]\n",
    "\n",
    "    confidence_list = []\n",
    "    for i in range(submission_data.shape[0]):\n",
    "        confidence_list_temp = []\n",
    "        for j in range(6):\n",
    "            confidence_list_temp.append(round(random.uniform(0, 1),3))\n",
    "            arr = np.array(confidence_list_temp)\n",
    "        confidence_list.append(arr)\n",
    "    submission_data['predicted_induced_state_confidence'] = confidence_list\n",
    "\n",
    "    three_sec_confidence_list = []\n",
    "    for i in range(submission_data.shape[0]):\n",
    "        three_sec_confidence_list_temp = []\n",
    "        for j in range(6):\n",
    "            three_sec_confidence_list_temp.append(round(random.uniform(0, 1),3))\n",
    "            arr = np.array(three_sec_confidence_list_temp)\n",
    "        three_sec_confidence_list.append(arr)\n",
    "    submission_data['three_sec_predicted_induced_state_confidence'] = three_sec_confidence_list\n",
    "\n",
    "    feature_list = final_cols[7:]\n",
    "    three_top_features = []\n",
    "    for i in range(submission_data.shape[0]):\n",
    "        three_top_features_temp = []\n",
    "        for j in range(3):\n",
    "            three_top_features_temp.append(random.choice(feature_list))\n",
    "            arr = np.array(three_top_features_temp)    \n",
    "        three_top_features.append(arr)\n",
    "    submission_data['top_three_features'] = three_top_features\n",
    "\n",
    "    submission_data.to_csv(output_file, index=False)\n",
    "\n",
    "    print('Testing finished.')\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
